input {
   kafka {
       bootstrap_servers => ["${KAFKA_BROKER_HOST}"]
       # id of us on Kafka side
       client_id => "logstash-errors"
       # consumer group for the topic - allows us to scale up logstash instances as needed and not duplicate logs in elastic
       group_id => "logstash-errors"
       topics => ["chaska-access-errors", "chaska-application-errors","hillsboro-access-errors", "hillsboro-application-errors", "centralus-azure-access-errors", "centralus-azure-application-errors"]
       codec => json {
         charset => "UTF-8"
       }
       # add Kafka [@metadata][kafka] fields
       decorate_events => "basic"
       consumer_threads => 10
   }
}

filter {
    if [@metadata][kafka][topic] =~ ".*-access-errors" {
        mutate {
            rename => { "[kubernetes][labels][app][kubernetes][io/component]" => "[kubernetes][labels][app.kubernetes.io/component]" }
            rename => { "[kubernetes][labels][app][kubernetes][io/instance]" => "[kubernetes][labels][app.kubernetes.io/instance]" }
            rename => { "[kubernetes][labels][app][kubernetes][io/name]" => "[kubernetes][labels][app.kubernetes.io/name]" }
            rename => { "[kubernetes][labels][app][kubernetes][io/version]" => "[kubernetes][labels][app.kubernetes.io/version]" }
        }
    }
    # rewrite legacy app labels to current standard.  This avoids https://jira.autodata.net/browse/CHRCSS-20645 which is essentially
    # the difference between seeing a field "app" vs "app -> kubernetes -> io/name".  Dynamic field mapping will configure the elastic index
    # so that "app == string"  or "app == object" depending on which it sees first.  Subsequently the other will cause an error and the
    # data will not be indexed.
    # if this is deployed and there is an existing index where "app" was processed first, the index will need to be deleted before it will work
    if [@metadata][kafka][topic] =~ ".*-application-errors" {
        if [kubernetes][labels][app] and ! [kubernetes][labels][app][kubernetes][io/name] {
            mutate {
                rename => { "[kubernetes][labels][app]" => "[kubernetes][labels][app.kubernetes.io/name]" }
            }
        }
    }
    mutate {

        add_field => { "[kafka][topic]" => "%{[@metadata][kafka][topic]}" }
        add_field => { "[kafka][consumer_group]" => "%{[@metadata][kafka][consumer_group]}" }
        add_field => { "[kafka][partition]" => "%{[@metadata][kafka][partition]}" }
        add_field => { "[kafka][offset]" => "%{[@metadata][kafka][offset]}" }
        add_field => { "[photon][timestamp]" => "%{[@timestamp]}" }
        remove_field => [
            "[agent]",
            "[log][file][path]",
            "[container]",
            "[kubernetes][container][image]",
            "[kubernetes][daemonset]",
            "[kubernetes][namespace_labels]",
            "[kubernetes][labels][controller-revision-hash]",
            "[kubernetes][labels][pod-template-hash]",
            "[kubernetes][labels][pod-template-generation]",
            "[kubernetes][pod][uid]",
            "[ecs][version]",
            "[input][type]",
            "[log][offset]"
        ]
    }
    date {
        match => [ "[photon][timestamp]" , "dd/MMM/yyyy:HH:mm:ss Z", "ISO8601" ]
    }
}

output {
    elasticsearch {
        # only .svc as the eck generated CA cert does not include our domain
        hosts => ["${ES_HOSTS}"]
        # Index is not required since we are using ILM which has an index associated already.
        #index => "%{[@metadata][target_index]}"
        user => "${ES_USER}"
        password => "${ES_PASSWORD}"
        ssl => "true"
        ssl_certificate_verification => "true"
        cacert => "/etc/logstash/certificates/ca.crt"
        ilm_enabled => true
        ilm_rollover_alias => "errors"
        ilm_policy => "errors"
    }
}
