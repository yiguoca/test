input {
   kafka {
       bootstrap_servers => ["${KAFKA_BROKER_HOST}"]
       # id of us on Kafka side
       client_id => "logstash-access"
       # consumer group for the topic - allows us to scale up logstash instances as needed and not duplicate logs in elastic
       group_id => "logstash-access"
       topics => ["chaska-access-logs", "hillsboro-access-logs","centralus-azure-access-logs"]
       codec => json {
         charset => "UTF-8"
       }
       # add Kafka [@metadata][kafka] fields
       decorate_events => "basic"
       consumer_threads => 10
   }
}

filter {
    if [message] =~ ".*\"http_user_agent\":\"Load Balancer Agent\".*"{
        drop{}
    }
    mutate {
        add_field => { "[photon][timestamp]" => "%{[@timestamp]}" }
    }
    if [@metadata][kafka][topic] =~ ".*-access-logs" {
        json {
            source => "message"
        }

        urldecode {
            field => "[nginx][query_params]"
        }

        # Fetch the language code from the request_uri.
        grok {
            match => {
                "[nginx][request_uri]" => ["\/(?<[photon][language_code]>\w\w)\/"]
            }
            tag_on_failure => []
        }

        # Locate photon api details from the request_uri.
        # The first match is for the new api pattern post configurator project in 2015 and the second match is for the old api url structure.
        # Another *hopefully* temporary pattern for incentives search endpoints that do not match typical hostd/api patterns.
        grok {
            match => {
                "[nginx][request_uri]" => [
                    "^(?i:\/hostd\/api\/(?i:(?<[photon][api][name]>incentives))\/(?<[photon][api][method]>offers|featuredmodel|advertisedmodelyear)\/(?<[photon][api][path_parameter_string]>\/?[\w\/-]*(?=(?:\/[\w-]*){2}))\/(?<[photon][api][resource]>\.?[^?#\n]*)\??(?<[photon][api][query_parameter_string]>[^#\n]*)\#?(?<[photon][api][anchor]>.*))$",
                    "^(?i:\/hostd\/api\/(?<[photon][api][name]>[\w-]+)(?<[photon][api][path_parameter_string]>\/?[\w\/-]*)\/(?<[photon][api][resource]>\.?[^?#]*)\??(?<[photon][api][query_parameter_string]>[^#]*)\#?(?<[photon][api][anchor]>.*))$",
                    "^(?i:\/(?<[photon][api][name]>hostd(?!\/api)[\/\w-]*)\/(?<[photon][api][resource]>\.?[^?#]*)\??(?<[photon][api][query_parameter_string]>[^#]*)\#?(?<[photon][api][anchor]>.*))$"
                ]
            }
            tag_on_failure => []
        }

        # Locate ccode and model_year_code in the request_uri.
        grok {
            match => {
                "[nginx][request_uri]" => ["\/(?<[photon][api][c_code]>[CI]U\w{14})?(?<[photon][api][model_year_code]>[CI]U\w{7})?\/"]
            }
            tag_on_failure => []
        }

        # Split the path parameters into a hash for simplified searching and visualization support in kibana
        if [photon][api][path_parameter_string] {
            mutate {
                gsub => [
                    "[photon][api][path_parameter_string]", "^\/\w\w\/", "/",
                    "[photon][api][path_parameter_string]", "/details", ""
                ]
            }
            kv {
                source => "[photon][api][path_parameter_string]"
                field_split => "/"
                value_split => "/"
                target => "[photon][api][path_parameters]"
            }
        }

        # Split the query parameters into a hash for simplified searching and visualization support in kibana
        if [photon][api][query_parameter_string] {
            kv {
                source => "[photon][api][query_parameter_string]"
                field_split => "&?"
                target => "[photon][api][query_parameters]"
            }
        } else {
            kv {
                source => "[nginx][query_params]"
                field_split => "&?"
                target => "[photon][query_parameters]"
            }
        }

        # Parse the CCode or Model Year Code into its constituent parts for simplified searching and visualization support in kibana
        # Check values parsed from request_uri first and then check query parameters. Also, favour ccode over model_year_code.
        if [photon][api][c_code] {
            grok {
                match => {
                    "[photon][api][c_code]" => [
                        "(?<[photon][api][catalog_code]>[CI])(?<[photon][api][market_code]>\w{1})(?<[photon][api][brand_code]>\w{1})(?<[photon][api][model_year]>\d{4})(?<[photon][api][model_code]>\d{2})(?<[photon][api][manufacturer_code]>\w{6})(?<[photon][api][variation_code]>\w{1})",
                        "(?<[photon][api][model_year_code]>[CI]\w{8})"
                    ]
                }
                break_on_match => false
                tag_on_failure => ["_grokparsefailure", "parse_codes_from_c_code"]
            }
        } else if [photon][api][model_year_code] {
            grok {
                match => {
                    "[photon][api][model_year_code]" => ["(?<[photon][api][catalog_code]>[CI])(?<[photon][api][market_code]>\w{1})(?<[photon][api][brand_code]>\w{1})(?<[photon][api][model_year]>\d{4})(?<[photon][api][model_code]>\d{2})"]
                }
                tag_on_failure => ["_grokparsefailure", "parse_codes_from_model_year_code"]
            }
        } else if [photon][api][query_parameters][ccode] {
            grok {
                match => {
                    "[photon][api][query_parameters][ccode]" => [
                        "(?<[photon][api][catalog_code]>[CI])(?<[photon][api][market_code]>\w{1})(?<[photon][api][brand_code]>\w{1})(?<[photon][api][model_year]>\d{4})(?<[photon][api][model_code]>\d{2})(?<[photon][api][manufacturer_code]>\w{6})(?<[photon][api][variation_code]>\w{1})",
                        "(?<[photon][api][model_year_code]>[CI]\w{8})"
                    ]
                }
                break_on_match => false
                tag_on_failure => ["_grokparsefailure", "parse_codes_from_c_code"]
            }
        } else if [photon][query_parameters][ccode] {
            grok {
                match => {
                    "[photon][query_parameters][ccode]" => [
                        "(?<[photon][api][catalog_code]>[CI])(?<[photon][api][market_code]>\w{1})(?<[photon][api][brand_code]>\w{1})(?<[photon][api][model_year]>\d{4})(?<[photon][api][model_code]>\d{2})(?<[photon][api][manufacturer_code]>\w{6})(?<[photon][api][variation_code]>\w{1})",
                        "(?<[photon][api][model_year_code]>[CI]\w{8})"
                    ]
                }
                break_on_match => false
                tag_on_failure => ["_grokparsefailure", "parse_codes_from_c_code"]
            }
        } else if [photon][api][query_parameters][modelYearCode] {
            grok {
                match => {
                    "[photon][api][query_parameters][modelYearCode]" => ["(?<[photon][api][catalog_code]>[CI])(?<[photon][api][market_code]>\w{1})(?<[photon][api][brand_code]>\w{1})(?<[photon][api][model_year]>\d{4})(?<[photon][api][model_code]>\d{2})"]
                }
                tag_on_failure => ["_grokparsefailure", "parse_codes_from_query_parameter_model_year_code"]
            }
        } else if [photon][query_parameters][modelYearCode] {
            grok {
                match => {
                    "[photon][query_parameters][modelYearCode]" => ["(?<[photon][api][catalog_code]>[CI])(?<[photon][api][market_code]>\w{1})(?<[photon][api][brand_code]>\w{1})(?<[photon][api][model_year]>\d{4})(?<[photon][api][model_code]>\d{2})"]
                }
                tag_on_failure => ["_grokparsefailure", "parse_codes_from_query_parameter_model_year_code"]
            }
        }

        # Evaluate nginx time_local field for a value matching accepted formats and parse it into a timestamp
        date {
            # 31/May/2022:14:17:18 +0000
            match => ["[nginx][time_local]", "dd/MM/YYYY:HH:mm:ss Z", "ISO8601", "dd/MMM/yyyy:HH:mm:ss Z"]
        }
    }
    mutate {
        add_field => { "[kafka][topic]" => "%{[@metadata][kafka][topic]}" }
        add_field => { "[kafka][partition]" => "%{[@metadata][kafka][partition]}" }
        add_field => { "[kafka][offset]" => "%{[@metadata][kafka][offset]}" }
        remove_field => [
            "[agent]",
            "[container]",
            "[ecs][version]",
            "[input][type]",
            "[kubernetes]",
            "[log][file][path]",
            "[log][offset]",
            "[message]",
            "[nginx][geoip]",
            "[nginx][query_params]",
            "[nginx][request_uri]",
            "[nginx][time_local]"
        ]
    }
}

output {
    elasticsearch {
        hosts => ["${ES_HOSTS}"]
        # Index is not required since we are using ILM which has an index associated already.
        #index => "%{[@metadata][target_index]}"
        user => "${ES_USER}"
        password => "${ES_PASSWORD}"
        ssl => "true"
        ssl_certificate_verification => "true"
        cacert => "/etc/logstash/certificates/ca.crt"
        ilm_enabled => true
        ilm_rollover_alias => "access"
        ilm_policy => "access"
    }
}